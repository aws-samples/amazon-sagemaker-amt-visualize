{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c090cbfa",
   "metadata": {},
   "source": [
    "## Notebook Setup and Uploading of Data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32b8dee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a738deca-4b24-453e-9655-03d2c016ce3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uq altair torchtext torchdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46f76095-552e-4cd3-9330-f334735a5697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7cf8d3c-31a2-4f7e-993e-4f3f870a0415",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p nn_src\n",
    "import sys\n",
    "sys.path.append('nn_src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21fe9f4d-91ef-47c7-981e-bfde1e897a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: nn_src/train_dummy to s3://sagemaker-eu-west-1-811243659808/nn/train_dummy\n"
     ]
    }
   ],
   "source": [
    "!touch nn_src/train_dummy\n",
    "BUCKET = sagemaker.Session().default_bucket()\n",
    "s3_data_url = f's3://{BUCKET}/nn/'\n",
    "!aws s3 sync nn_src {s3_data_url} --exclude '*' --include 'train_dummy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27324d73-b450-4a41-a79e-ad45379a9be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting nn_src/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile nn_src/requirements.txt\n",
    "torchtext\n",
    "torchdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30514f65-421d-4c0c-b003-c4896322fab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting nn_src/trenc.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile nn_src/trenc.py\n",
    "\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F \n",
    "from torch import log\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 d,\n",
    "                 num_heads,\n",
    "                 dropout,\n",
    "                 res_connections=True):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        projection_size = d // num_heads\n",
    "\n",
    "        self.WQ = nn.Parameter(torch.randn(num_heads, d, projection_size)/math.sqrt(d))\n",
    "        self.WK = nn.Parameter(torch.randn(num_heads, d, projection_size)/math.sqrt(d))\n",
    "        self.WV = nn.Parameter(torch.randn(num_heads, d, projection_size)/math.sqrt(d))\n",
    "        self.WO = nn.Parameter(torch.randn(num_heads, projection_size, d)/math.sqrt(d))\n",
    "\n",
    "        self.attn_norm = nn.LayerNorm(d)\n",
    "        self.ff_norm   = nn.LayerNorm(d)\n",
    "        self.dropout   = nn.Dropout(p=dropout)\n",
    "        self.ff        = nn.Sequential(\n",
    "            nn.Linear(d, 4*d), \n",
    "            nn.GELU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(4*d, d)\n",
    "        )\n",
    "\n",
    "        self.res_connections = res_connections\n",
    "        # Why just one ReLU/GELU, one dropout? Attention is all you need: 4.3, 5.4. \n",
    "        \n",
    "    def forward(self, input):\n",
    "\n",
    "        X, prv_attention_values = input\n",
    "\n",
    "        # b batch\n",
    "        # t step\n",
    "        # d dimension\n",
    "        # p projected dimension\n",
    "        # h head\n",
    "        \n",
    "        normalized_X = self.attn_norm(X) # Pre-Norm\n",
    "\n",
    "        # Creating keys, queries and values from the normalized values, while\n",
    "        # at the same time down projecting from d dimensions to p dimensions\n",
    "        keys    = torch.einsum('btd,hdp->bthp', normalized_X, self.WK)\n",
    "        queries = torch.einsum('btd,hdp->bthp', normalized_X, self.WQ)\n",
    "        values  = torch.einsum('btd,hdp->bthp', normalized_X, self.WV)\n",
    "\n",
    "        # Attention values are per position, not per dimension etc.\n",
    "        dot = torch.einsum('bkhp,bqhp->bhqk', queries, keys)\n",
    "        scaled_dot = dot / math.sqrt(values.size()[-1])\n",
    "        attention_values = torch.softmax(scaled_dot, -1)\n",
    "\n",
    "        assert torch.allclose(attention_values[0, 0, 0].sum(), torch.tensor(1.))\n",
    "\n",
    "        new_values = torch.einsum('bkhp,bhqk->bqhp', values, attention_values)\n",
    "        b, t, h, p = new_values.size()\n",
    "\n",
    "        # Consolidate the invidual head outputs by concenating them\n",
    "        # and then up projecting from p to d dimensions.\n",
    "        seq_summary = torch.einsum('bthp,hpd->btd', new_values, self.WO)\n",
    "        \n",
    "        # Alternatively: \n",
    "        # Concat outputs of the individual heads\n",
    "        # Using no learnable parameters\n",
    "        # seq_summary = new_values.view(b, t, -1)\n",
    "\n",
    "        assert seq_summary.size()[-1] == h*p == X.size()[-1]\n",
    "\n",
    "        # Residual Connection and Pre-Norm\n",
    "        if self.res_connections:\n",
    "            pre_ff = X + self.ff_norm(seq_summary) \n",
    "        else:\n",
    "            pre_ff = self.ff_norm(seq_summary) \n",
    "\n",
    "        prv_attention_values.append(attention_values)\n",
    "\n",
    "        post_ff = self.ff(self.dropout(pre_ff))\n",
    "        if self.res_connections:\n",
    "            return post_ff + pre_ff, prv_attention_values\n",
    "        else:\n",
    "            return post_ff, prv_attention_values\n",
    "\n",
    "\n",
    "class TrEnc(nn.Module):\n",
    "    def __init__(self, \n",
    "                 num_classes, \n",
    "                 vocab_size, \n",
    "                 layers,\n",
    "                 d,\n",
    "                 heads,\n",
    "                 dropout,\n",
    "                 use_pos_enc,\n",
    "                 use_cls_token,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        res_connections=True\n",
    "        pos_encoding = 'sin' if use_pos_enc else None\n",
    "        \n",
    "        embed_size = d*heads \n",
    "        self.pooling  = 'cls' if use_cls_token else 'mean'\n",
    "        \n",
    "        self.res_connections = res_connections == True\n",
    "  \n",
    "        self.embeddings = nn.Embedding(vocab_size, embed_size, padding_idx=1)\n",
    "\n",
    "        self.encoder_layers = \\\n",
    "            nn.Sequential(\n",
    "                *[EncoderLayer(embed_size, heads, dropout, res_connections) for _ in range(layers)],)\n",
    "\n",
    "        # Empricially it was a toss-up if the additional LN helped or not\n",
    "        # It is part of the Pre-LN Transformer though\n",
    "                #nn.LayerNorm(embed_size))\n",
    "        \n",
    "        # REVIEW: Just have one matrix for all three weight matrices?\n",
    "        # REVIEW: Maybe do not project the values, but q and k only\n",
    "        \n",
    "        self.dropout     = nn.Dropout(p=dropout)\n",
    "        #self.clf         = nn.Linear(embed_size, num_classes)\n",
    "        self.clf = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.LayerNorm(embed_size),\n",
    "            nn.Linear(embed_size, embed_size//2, bias=False),\n",
    "            nn.GELU(),\n",
    "\n",
    "            nn.Dropout(dropout),\n",
    "            nn.LayerNorm(embed_size//2),\n",
    "            nn.Linear(embed_size//2, num_classes)\n",
    "        )\n",
    "        \n",
    "        self.pos_encoder = None\n",
    "\n",
    "        if 'simple' == pos_encoding:\n",
    "            self.pos_encoder = SimplePositionalEncoding(dropout)\n",
    "        elif 'sin' == pos_encoding: \n",
    "            self.pos_encoder = PositionalEncoding(embed_size, dropout)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f'residual_connection={self.res_connections}, pooling={self.pooling}'\n",
    "\n",
    "    def forward(self, X, output_attentions=False):\n",
    "        # TODO: Unclear how helpful dropout on embeddings is here. Same p? \n",
    "        emb = self.dropout(self.embeddings(X))\n",
    "\n",
    "        if self.pos_encoder:\n",
    "            emb = self.pos_encoder(emb) \n",
    "\n",
    "        z, attention_values = self.encoder_layers((emb, []))\n",
    "        \n",
    "        if self.pooling == 'cls':\n",
    "            logits = self.clf(self.dropout(z[:, 0]))\n",
    "        elif self.pooling == 'mean':\n",
    "            logits = self.clf(self.dropout(z.mean(1)))\n",
    "        else:\n",
    "            raise ValueError('Only mean and cls are valid valued for pooling.')\n",
    "\n",
    "        if output_attentions:\n",
    "            # return attention as b, l, h, q, k\n",
    "            return logits, torch.stack(attention_values, 0).transpose(0, 1)\n",
    "        return logits\n",
    "\n",
    "class SimplePositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc = torch.arange(-1., 1., step=64, device=x.device)[:, None]\n",
    "        x = x + self.dropout(enc) \n",
    "        return x\n",
    "\n",
    "# From: https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f81483f-4119-47d5-9b76-821d8d880d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting nn_src/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile nn_src/model.py\n",
    "\n",
    "import math\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class SentimentNN(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        num_classes, \n",
    "        vocab_size, \n",
    "        layers, \n",
    "        d, \n",
    "        heads, \n",
    "        dropout, \n",
    "        use_pos_enc, \n",
    "        use_cls_token, \n",
    "        *args, \n",
    "        **kwargs\n",
    "    ): \n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_classes   = num_classes\n",
    "        self.use_cls_token = use_cls_token\n",
    "        \n",
    "        # the dimensions of the embeddings must be divisible by the number of heads. \n",
    "        # Therefore we specify them this way.\n",
    "        dh = d*heads \n",
    "        layer = nn.TransformerEncoderLayer(\n",
    "            d_model=dh, \n",
    "            nhead=heads, \n",
    "            dim_feedforward=dh*4,\n",
    "            norm_first=True,\n",
    "            activation='gelu',\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        self.trenc = nn.TransformerEncoder(\n",
    "            layer, \n",
    "            num_layers=layers\n",
    "        )\n",
    "        \n",
    "        self.clf = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.LayerNorm(dh),\n",
    "            nn.Linear(dh, dh//2, bias=False),\n",
    "            nn.GELU(),\n",
    "            \n",
    "            nn.Dropout(dropout),\n",
    "            nn.LayerNorm(dh//2),\n",
    "            nn.Linear(dh//2, num_classes)\n",
    "        )\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_size, dh, padding_idx=1)\n",
    "        \n",
    "        self.pos_enc = PositionalEncoding(dh, dropout=dropout) if use_pos_enc else None\n",
    "            \n",
    "    def forward(self, x):\n",
    "        enc = self.emb(x)\n",
    "        \n",
    "        if self.pos_enc:\n",
    "            enc = self.pos_enc(enc)\n",
    "        \n",
    "        h = self.trenc(enc)\n",
    "        if self.use_cls_token:\n",
    "            h = h[:, 0, :]\n",
    "        else:\n",
    "            h = h.mean(-2)\n",
    "            \n",
    "        return self.clf(h)\n",
    "        \n",
    "        #enc = self.enc(x)[:, 0, :] # Just the first element\n",
    "        #enc = self.enc(x).mean(-2) # Just the first element\n",
    "        \n",
    "        #enc = self.emb(x).mean(-2)\n",
    "        #return self.clf(enc)\n",
    "    \n",
    "    def extra_repr(self):\n",
    "        return f'num_classes: {self.num_classes} use_pos_enc: {self.pos_enc is not None} use_cls_token: {self.use_cls_token}'\n",
    "    \n",
    "# From: https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5_000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10_000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d6aeed9-0847-458f-b873-a6b41d15c0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting nn_src/util.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile nn_src/util.py\n",
    "\n",
    "def count_parameters(m, verbose=True):\n",
    "    total_count = 0\n",
    "    learnable_count = 0\n",
    "    if verbose:\n",
    "        print('Parameters (name, tunable, count):')\n",
    "    for n, p in m.named_parameters():\n",
    "        count = p.data.numel() \n",
    "        if verbose:\n",
    "            print(f' {n:60s} {p.requires_grad:5b} {count:>9d}')\n",
    "        total_count += count\n",
    "        if p.requires_grad:\n",
    "            learnable_count += count\n",
    "    if verbose:\n",
    "        print(f'Total parameters: {total_count}, thereof learnable: {learnable_count}')\n",
    "    return total_count, learnable_count\n",
    "\n",
    "def str2bool(v):\n",
    "    if isinstance(v, bool):\n",
    "        return v\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cb6076f-adc5-4a2a-96c5-b4806d11896c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting nn_src/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile nn_src/train.py\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "import random\n",
    "import math\n",
    "from time import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchdata.datapipes as dp\n",
    "\n",
    "from torchtext.datasets import IMDB\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "from util import str2bool, count_parameters\n",
    "from model import SentimentNN\n",
    "from trenc import TrEnc\n",
    "\n",
    "def parse_args(arg_values_to_parse):\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--model', type=str, default='SentimentNN') \n",
    "    parser.add_argument('--epochs', type=int, default=1) \n",
    "    parser.add_argument('--early-stopping-patience', type=int, default=0)\n",
    "    parser.add_argument('--batch-size', dest='bs', type=int, default=32) \n",
    "    parser.add_argument('--lr', type=float, default=5e-5) \n",
    "    \n",
    "    parser.add_argument('--vocab-size',    type=int, default=10_000) \n",
    "    parser.add_argument('--max-input-len', type=int, default=64) \n",
    "    \n",
    "    # model\n",
    "    parser.add_argument('--dropout', dest='m_dropout',type=float, default=0.2) \n",
    "    parser.add_argument('--layers',  dest='m_layers',type=int, default=1) \n",
    "    parser.add_argument('--heads',   dest='m_heads', type=int, default=8) \n",
    "    parser.add_argument('--dim',     dest='m_d',     type=int, default=64) \n",
    "    parser.add_argument('--use-cls-token', dest='m_use_cls_token', type=str2bool, default=True)\n",
    "    parser.add_argument('--use-pos-enc',   dest='m_use_pos_enc',   type=str2bool, default=False)\n",
    "    \n",
    "    parser.add_argument('--dummy', dest='_ignore',type=float, default=0.) \n",
    "    \n",
    "    \n",
    "    # FIXME: Should I add a separate pooler?\n",
    "        \n",
    "    return parser.parse_args(arg_values_to_parse)\n",
    "\n",
    "def main(*arg_values_to_parse):\n",
    "    \n",
    "    args = parse_args([str(la) for la in arg_values_to_parse])\n",
    "    print('Arguments:', args)\n",
    "  \n",
    "    dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    \n",
    "    ### Data\n",
    "    train_dp, valid_dp = IMDB(root='imdb_data', split=('train', 'test'))\n",
    "    \n",
    "    ### Built vocab and tokenizer\n",
    "    tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "    vocab = build_vocab_from_iterator(\n",
    "        map(tokenizer, (text for (_, text) in train_dp)), specials=['<UNK>', '<PAD>'], \n",
    "        max_tokens=args.vocab_size\n",
    "    )\n",
    "    vocab.set_default_index(vocab['<UNK>'])\n",
    "    \n",
    "    print(f'Vocabulary built with {len(vocab.get_itos())} tokens.')\n",
    "    \n",
    "    ### Data Loader\n",
    "    def vectorize(y, x):\n",
    "        y = 0 if y == 'neg' else 1\n",
    "        return (y, vocab(tokenizer(x)))\n",
    "    \n",
    "    def collate(data):\n",
    "        batch_len = min(args.max_input_len, max([len(x) for (_, x) in data]))\n",
    "        \n",
    "        padding = [1] * batch_len # <PAD> has index 1\n",
    "        y, x = zip(*[(y, (x+padding)[:batch_len]) for (y, x) in data])\n",
    " \n",
    "        return torch.LongTensor(y).to(dev), torch.LongTensor(x).to(dev)\n",
    "    \n",
    "    train_dl = DataLoader(\n",
    "        dataset=[vectorize(y, x) for (y, x) in train_dp], \n",
    "        batch_size=args.bs, \n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        collate_fn=collate)\n",
    "    del train_dp\n",
    "    \n",
    "    valid_ds = [vectorize(y, x) for (y, x) in valid_dp]\n",
    "    random.shuffle(valid_ds)\n",
    "    valid_dl = DataLoader(\n",
    "        dataset=valid_ds[:7500], \n",
    "                batch_size=args.bs*2,\n",
    "                collate_fn=collate)  \n",
    "    del valid_dp\n",
    "    del valid_ds\n",
    "    \n",
    "    ### Model\n",
    "    # Instantiate model and pass all command line args that start with m_\n",
    "    if args.model == 'SentimentNN':\n",
    "        model = SentimentNN(\n",
    "            num_classes=2, # neg, pos \n",
    "            vocab_size=len(vocab.get_itos()),\n",
    "            **{k[2:]: v for k, v in vars(args).items() if k.startswith('m_')}, \n",
    "        ).to(dev)\n",
    "    else:\n",
    "        model = TrEnc(\n",
    "            num_classes=2, # neg, pos \n",
    "            vocab_size=len(vocab.get_itos()),\n",
    "            **{k[2:]: v for k, v in vars(args).items() if k.startswith('m_')}, \n",
    "        ).to(dev)\n",
    "        \n",
    "    print('Model instantiated:', model)\n",
    "\n",
    "    # prints 'learnable: ddd' to stdout\n",
    "    count_parameters(model)[1]\n",
    "    \n",
    "    ### Train Loop\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr)\n",
    "    criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "        \n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    best_valid_loss = math.inf\n",
    "    best_epoch = None\n",
    "    \n",
    "    #FIXME: documentation.\n",
    "    best_result_store = None \n",
    "    \n",
    "    for epoch in range(args.epochs):\n",
    "        model.train()\n",
    "        train_loss_epoch = 0.\n",
    "        train_count_epoch = 0\n",
    "        started = time()\n",
    "    \n",
    "        for i, (Yb, Xb) in enumerate(train_dl): \n",
    "            \n",
    "            with torch.cuda.amp.autocast():\n",
    "                logits = model(Xb)\n",
    "            \n",
    "                loss = criterion(logits, Yb)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            train_loss_epoch  += loss.item() \n",
    "            train_count_epoch += len(Yb)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if i % 50 == 0: \n",
    "                print(f'i: {i:4d}: batch_train_loss: {loss/len(Yb):6.4f}')\n",
    "                \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_count_epoch = 0\n",
    "            matched_epoch = 0\n",
    "            valid_loss_epoch = 0.\n",
    "            \n",
    "            for i, (Yb, Xb) in enumerate(valid_dl):\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    logits = model(Xb)\n",
    "                    valid_loss_epoch += criterion(logits, Yb).item()\n",
    "                    \n",
    "                    predictions = logits.argmax(-1)\n",
    "                    matched_epoch += (predictions == Yb).sum().item()\n",
    "                    valid_count_epoch += len(Yb)\n",
    "\n",
    "            acc = matched_epoch/valid_count_epoch\n",
    "        \n",
    "        log_message = f'ep: {epoch} train_loss: {train_loss_epoch/train_count_epoch:6.5f} valid_loss: {valid_loss_epoch/valid_count_epoch:6.5f} valid_acc: {acc:5.4f} took: {time()-started:5.3f}s'\n",
    "        print(log_message)\n",
    "        \n",
    "        if valid_loss_epoch < best_valid_loss:\n",
    "            best_valid_loss = valid_loss_epoch\n",
    "            best_result_store = log_message\n",
    "            best_epoch = epoch\n",
    "            \n",
    "            print(f'epoch {epoch} was the best epoch so far.')\n",
    "            \n",
    "        # early stopping \n",
    "        print(f'best epoch {best_epoch}, epoch {epoch}, diff {(epoch-best_epoch)}')\n",
    "        if best_epoch and epoch >= args.early_stopping_patience-1 and (epoch-best_epoch) >= args.early_stopping_patience:\n",
    "            print(f'No progress for {args.early_stopping_patience} epochs. Stopping early.')\n",
    "            break\n",
    "                \n",
    "    print('End of training.')\n",
    "    print('Re-reporting best loss epoch:')\n",
    "    print(best_result_store)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('main', sys.argv)\n",
    "    main(*sys.argv[1:])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb3506f-637c-4fa6-8b84-39584c365d44",
   "metadata": {},
   "source": [
    "!0!2.0\n",
    "!1!1.5\n",
    "!2!1.3\n",
    "!3!1.3 (last improvement)\n",
    "!4!1.4\n",
    "!5!1.5\n",
    "!6!1.6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "36fb6213-00b1-484e-adeb-65dd28bc289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python nn_src/train.py --epochs 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "22c68527-daec-4406-85f1-dbaa0f72d10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments: Namespace(model='TrEnc', epochs=200, early_stopping_patience=2, bs=128, lr=0.1, vocab_size=1000, max_input_len=256, m_dropout=0.2, m_layers=1, m_heads=2, m_d=8, m_use_cls_token=True, m_use_pos_enc=False, _ignore=0.0)\n",
      "Vocabulary built with 1000 tokens.\n",
      "Model instantiated: TrEnc(\n",
      "  residual_connection=True, pooling=cls\n",
      "  (embeddings): Embedding(1000, 16, padding_idx=1)\n",
      "  (encoder_layers): Sequential(\n",
      "    (0): EncoderLayer(\n",
      "      (attn_norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "      (ff_norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (ff): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=64, bias=True)\n",
      "        (1): GELU(approximate=none)\n",
      "        (2): Dropout(p=0.2, inplace=False)\n",
      "        (3): Linear(in_features=64, out_features=16, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (clf): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "    (2): Linear(in_features=16, out_features=8, bias=False)\n",
      "    (3): GELU(approximate=none)\n",
      "    (4): Dropout(p=0.2, inplace=False)\n",
      "    (5): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "    (6): Linear(in_features=8, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Parameters (name, tunable, count):\n",
      " embeddings.weight                                                1     16000\n",
      " encoder_layers.0.WQ                                              1       256\n",
      " encoder_layers.0.WK                                              1       256\n",
      " encoder_layers.0.WV                                              1       256\n",
      " encoder_layers.0.WO                                              1       256\n",
      " encoder_layers.0.attn_norm.weight                                1        16\n",
      " encoder_layers.0.attn_norm.bias                                  1        16\n",
      " encoder_layers.0.ff_norm.weight                                  1        16\n",
      " encoder_layers.0.ff_norm.bias                                    1        16\n",
      " encoder_layers.0.ff.0.weight                                     1      1024\n",
      " encoder_layers.0.ff.0.bias                                       1        64\n",
      " encoder_layers.0.ff.3.weight                                     1      1024\n",
      " encoder_layers.0.ff.3.bias                                       1        16\n",
      " clf.1.weight                                                     1        16\n",
      " clf.1.bias                                                       1        16\n",
      " clf.2.weight                                                     1       128\n",
      " clf.5.weight                                                     1         8\n",
      " clf.5.bias                                                       1         8\n",
      " clf.6.weight                                                     1        16\n",
      " clf.6.bias                                                       1         2\n",
      "Total parameters: 19410, thereof learnable: 19410\n",
      "i:    0: batch_train_loss: 0.7490\n",
      "i:   50: batch_train_loss: 0.6890\n",
      "i:  100: batch_train_loss: 0.6953\n",
      "i:  150: batch_train_loss: 0.6974\n",
      "ep: 0 train_loss: 0.69713 valid_loss: 0.69823 valid_acc: 0.4964 took: 22.722s\n",
      "epoch 0 was the best epoch so far.\n",
      "best epoch 0, epoch 0, diff 0\n",
      "i:    0: batch_train_loss: 0.7053\n",
      "i:   50: batch_train_loss: 0.7000\n",
      "i:  100: batch_train_loss: 0.6927\n",
      "i:  150: batch_train_loss: 0.6928\n",
      "ep: 1 train_loss: 0.69540 valid_loss: 0.70286 valid_acc: 0.4964 took: 22.527s\n",
      "best epoch 0, epoch 1, diff 1\n",
      "i:    0: batch_train_loss: 0.6908\n",
      "i:   50: batch_train_loss: 0.6872\n",
      "i:  100: batch_train_loss: 0.7015\n",
      "i:  150: batch_train_loss: 0.7576\n",
      "ep: 2 train_loss: 0.69835 valid_loss: 0.69509 valid_acc: 0.4964 took: 22.470s\n",
      "epoch 2 was the best epoch so far.\n",
      "best epoch 2, epoch 2, diff 0\n",
      "i:    0: batch_train_loss: 0.7030\n",
      "i:   50: batch_train_loss: 0.6929\n",
      "i:  100: batch_train_loss: 0.6868\n",
      "i:  150: batch_train_loss: 0.6868\n",
      "ep: 3 train_loss: 0.69612 valid_loss: 0.69320 valid_acc: 0.5036 took: 22.398s\n",
      "epoch 3 was the best epoch so far.\n",
      "best epoch 3, epoch 3, diff 0\n",
      "i:    0: batch_train_loss: 0.6924\n",
      "i:   50: batch_train_loss: 0.7012\n",
      "i:  100: batch_train_loss: 0.6909\n",
      "i:  150: batch_train_loss: 0.7013\n",
      "ep: 4 train_loss: 0.69734 valid_loss: 0.69376 valid_acc: 0.4964 took: 22.530s\n",
      "best epoch 3, epoch 4, diff 1\n",
      "i:    0: batch_train_loss: 0.6910\n",
      "i:   50: batch_train_loss: 0.6941\n",
      "i:  100: batch_train_loss: 0.6910\n",
      "i:  150: batch_train_loss: 0.6966\n",
      "ep: 5 train_loss: 0.69580 valid_loss: 0.72529 valid_acc: 0.4964 took: 23.032s\n",
      "best epoch 3, epoch 5, diff 2\n",
      "No progress for 2 epochs. Stopping early.\n",
      "End of training.\n",
      "Re-reporting best loss epoch:\n",
      "ep: 3 train_loss: 0.69612 valid_loss: 0.69320 valid_acc: 0.5036 took: 22.398s\n"
     ]
    }
   ],
   "source": [
    "from nn_src.train import main as fit\n",
    "fit('--epochs', 200,\n",
    "    '--vocab-size', 1_000,\n",
    "    '--batch-size', 128,\n",
    "    '--lr', 1e-1, \n",
    "    '--layers', 1,\n",
    "    '--dim', 8,\n",
    "    '--heads', 2,\n",
    "    '--max-input-len', 256,\n",
    "    '--model', 'TrEnc',\n",
    "    '--early-stopping-patience', 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab962ac-7c05-4577-a5d5-9ddd5b673591",
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9b8ef01-400d-4920-9ab9-4afb5536f3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdc82cd2-9423-4d8d-a5dd-b7907672e013",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "    {'Name': 'Epoch',               'Regex': r'ep:\\s+(-?[0-9\\.]+)'},\n",
    "    {'Name': 'Valid:Acc',           'Regex': r'valid_acc:\\s+(-?[0-9\\.]+)'},\n",
    "    {'Name': 'Train:Loss',          'Regex': r'train_loss:\\s+(-?[0-9\\.]+)'},\n",
    "    {'Name': 'Valid:Loss',          'Regex': r'valid_loss:\\s+(-?[0-9\\.]+)'}, \n",
    "    {'Name': 'LearnableParameters', 'Regex': r'learnable:\\s+(-?[0-9\\.]+)'} \n",
    "]                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5ba2144-8bf1-40d5-8e00-04bc24a36f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = PyTorch('train.py',\n",
    "                    source_dir='nn_src',\n",
    "                    role=get_execution_role(),\n",
    "                    instance_type= 'ml.g4dn.xlarge',\n",
    "                    instance_count=1,\n",
    "                    framework_version='1.10',\n",
    "                    py_version='py38',\n",
    "                    metric_definitions=metric_definitions,\n",
    "                    base_job_name='nn',\n",
    "                    \n",
    "                    use_spot_instances= True,\n",
    "                    max_run=  60 * 60 * 24,\n",
    "                    max_wait= 60 * 60 * 24,\n",
    "                    \n",
    "                    keep_alive_period_in_seconds= 120,\n",
    "                    \n",
    "                    hyperparameters = {'early-stopping-patience': 4, \n",
    "                                       'epochs': 20,\n",
    "                                       'batch-size': 128,\n",
    "                                       'lr': 2e-4,\n",
    "                                       'vocab-size': 10_000,\n",
    "                                       'heads': 12,\n",
    "                                       'dim': 32, \n",
    "                                       'max-input-len': 256,\n",
    "                                       'layers': 1,\n",
    "                                       'dropout': 0.2, \n",
    "                                       'use-cls-token': True,\n",
    "                                       'use-pos-enc': True,\n",
    "                                       'model': 'TrEnc'}) # SentimentNN, TrEnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "81948f79-5caa-4d3e-b0c2-dcf3ac2a54cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimator.fit({'train': s3_data_url+'train_dummy'}, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b837a7-296b-4d44-a6b5-7c9a0b3f7448",
   "metadata": {},
   "source": [
    "### Automatic Model Tuning Jobs\n",
    "#### Random Sweep to check the lay of the land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8472245d-2453-407d-b758-12ef33cb8565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter\n",
    "from sagemaker.tuner import ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "hpt_ranges = {\n",
    "    #'dummy': ContinuousParameter(1e-7, 1e-1), \n",
    "    #'vocab-size': IntegerParameter(1_000, 10_000),\n",
    "    'lr': ContinuousParameter(1e-6, 1e-1), \n",
    "    #'max-input-len': IntegerParameter(100, 1_000),\n",
    "    #'dropout': ContinuousParameter(0.00, 0.6),\n",
    "    #'heads': IntegerParameter(4, 16),\n",
    "    #'dim': IntegerParameter(32, 96),\n",
    "    #'layers': IntegerParameter(1, 12),\n",
    "    #'model': CategoricalParameter(['SentimentNN', 'TrEnc']),\n",
    "    #'use-pos-enc': CategoricalParameter([True, False]),\n",
    "    #'use-cls-token': CategoricalParameter([True, False])\n",
    "}\n",
    "\n",
    "tuner_parameters = {'estimator': estimator,\n",
    "                    'base_tuning_job_name': 'model-lr-nn',\n",
    "                    'metric_definitions': metric_definitions,\n",
    "                    \n",
    "                    'objective_metric_name': 'Valid:Acc',\n",
    "                    'objective_type': 'Maximize',\n",
    "                    'hyperparameter_ranges': hpt_ranges,\n",
    "                    'strategy': 'Bayesian',\n",
    "                    'early_stopping_type': 'Auto',\n",
    "                    \n",
    "                    'max_jobs': 15,           # Was: 20 \n",
    "                    'max_parallel_jobs': 1}   # Was: 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "94d4b501-0c3b-444d-a778-b9dfb9dac182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuning job submitted: model-lr-nn-221021-1022.\n"
     ]
    }
   ],
   "source": [
    "tuner = HyperparameterTuner(**tuner_parameters)\n",
    "tuner.fit({'train': s3_data_url+'train_dummy'}, wait=False)\n",
    "tuner_name = tuner.describe()[\"HyperParameterTuningJobName\"]\n",
    "print(f'tuning job submitted: {tuner_name}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72353ba3-09e9-4b5e-9bc4-cae226d5d600",
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = 'model-221020-1931'\n",
    "layers = 'layers-221020-1931'\n",
    "md_lr = ['model-lr-tr-221020-2000', 'model-lr-nn-221020-2001', 'model-lr-nn-221021-1022']\n",
    "pos_enc = 'pos-enc-221020-2003'\n",
    "pos_enc_lr = ['pe-t-lr-221020-2140', 'pe-f-lr-221020-2141']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e704b797-add1-44ff-82b2-4720f976241c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15480291-4dab-4fe0-b59f-ac66ff8604cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mkamp/code/amazon-sagemaker-amt-visualize\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aad268-e6ea-4fdb-9518-f9025782d050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning job model-lr-tr-221020-2000   status: Completed\n",
      "Tuning job model-lr-nn-221020-2001   status: Completed\n",
      "Tuning job model-lr-nn-221021-1022   status: Stopped\n",
      "\n",
      "Number of training jobs with valid objective: 50\n",
      "Lowest: 0.5076000094413757 Highest 0.8151000142097473\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "      <th>TuningJobName</th>\n",
       "      <th>Valid:Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000447</td>\n",
       "      <td>model-lr-tr-221020-2000-010-21c4f7b4</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2022-10-20 22:14:04+02:00</td>\n",
       "      <td>2022-10-20 22:25:54+02:00</td>\n",
       "      <td>710.0</td>\n",
       "      <td>model-lr-tr-221020-2000</td>\n",
       "      <td>0.8151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000698</td>\n",
       "      <td>model-lr-tr-221020-2000-020-80d7c4e0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2022-10-21 00:39:21+02:00</td>\n",
       "      <td>2022-10-21 00:51:35+02:00</td>\n",
       "      <td>734.0</td>\n",
       "      <td>model-lr-tr-221020-2000</td>\n",
       "      <td>0.8104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000478</td>\n",
       "      <td>model-lr-tr-221020-2000-019-599b0f9d</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2022-10-21 00:25:12+02:00</td>\n",
       "      <td>2022-10-21 00:37:12+02:00</td>\n",
       "      <td>720.0</td>\n",
       "      <td>model-lr-tr-221020-2000</td>\n",
       "      <td>0.8079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000529</td>\n",
       "      <td>model-lr-tr-221020-2000-007-6fb682d4</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2022-10-20 21:31:18+02:00</td>\n",
       "      <td>2022-10-20 21:43:41+02:00</td>\n",
       "      <td>743.0</td>\n",
       "      <td>model-lr-tr-221020-2000</td>\n",
       "      <td>0.8064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000602</td>\n",
       "      <td>model-lr-tr-221020-2000-009-953d7280</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2022-10-20 21:59:48+02:00</td>\n",
       "      <td>2022-10-20 22:11:58+02:00</td>\n",
       "      <td>730.0</td>\n",
       "      <td>model-lr-tr-221020-2000</td>\n",
       "      <td>0.7997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000256</td>\n",
       "      <td>model-lr-tr-221020-2000-006-136ed090</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2022-10-20 21:16:50+02:00</td>\n",
       "      <td>2022-10-20 21:29:25+02:00</td>\n",
       "      <td>755.0</td>\n",
       "      <td>model-lr-tr-221020-2000</td>\n",
       "      <td>0.7969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000801</td>\n",
       "      <td>model-lr-tr-221020-2000-015-cfbc67df</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2022-10-20 23:28:09+02:00</td>\n",
       "      <td>2022-10-20 23:40:19+02:00</td>\n",
       "      <td>730.0</td>\n",
       "      <td>model-lr-tr-221020-2000</td>\n",
       "      <td>0.7968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000126</td>\n",
       "      <td>model-lr-tr-221020-2000-013-175d72a6</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2022-10-20 22:59:37+02:00</td>\n",
       "      <td>2022-10-20 23:11:46+02:00</td>\n",
       "      <td>729.0</td>\n",
       "      <td>model-lr-tr-221020-2000</td>\n",
       "      <td>0.7955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000268</td>\n",
       "      <td>model-lr-tr-221020-2000-002-ba9388a9</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2022-10-20 20:16:40+02:00</td>\n",
       "      <td>2022-10-20 20:29:00+02:00</td>\n",
       "      <td>740.0</td>\n",
       "      <td>model-lr-tr-221020-2000</td>\n",
       "      <td>0.7927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000026</td>\n",
       "      <td>model-lr-tr-221020-2000-012-5ae01165</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2022-10-20 22:45:18+02:00</td>\n",
       "      <td>2022-10-20 22:57:18+02:00</td>\n",
       "      <td>720.0</td>\n",
       "      <td>model-lr-tr-221020-2000</td>\n",
       "      <td>0.7905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lr                       TrainingJobName TrainingJobStatus         TrainingStartTime           TrainingEndTime  TrainingElapsedTimeSeconds            TuningJobName  Valid:Acc\n",
       "10  0.000447  model-lr-tr-221020-2000-010-21c4f7b4         Completed 2022-10-20 22:14:04+02:00 2022-10-20 22:25:54+02:00                       710.0  model-lr-tr-221020-2000     0.8151\n",
       "0   0.000698  model-lr-tr-221020-2000-020-80d7c4e0         Completed 2022-10-21 00:39:21+02:00 2022-10-21 00:51:35+02:00                       734.0  model-lr-tr-221020-2000     0.8104\n",
       "1   0.000478  model-lr-tr-221020-2000-019-599b0f9d         Completed 2022-10-21 00:25:12+02:00 2022-10-21 00:37:12+02:00                       720.0  model-lr-tr-221020-2000     0.8079\n",
       "13  0.000529  model-lr-tr-221020-2000-007-6fb682d4         Completed 2022-10-20 21:31:18+02:00 2022-10-20 21:43:41+02:00                       743.0  model-lr-tr-221020-2000     0.8064\n",
       "11  0.000602  model-lr-tr-221020-2000-009-953d7280         Completed 2022-10-20 21:59:48+02:00 2022-10-20 22:11:58+02:00                       730.0  model-lr-tr-221020-2000     0.7997\n",
       "14  0.000256  model-lr-tr-221020-2000-006-136ed090         Completed 2022-10-20 21:16:50+02:00 2022-10-20 21:29:25+02:00                       755.0  model-lr-tr-221020-2000     0.7969\n",
       "5   0.000801  model-lr-tr-221020-2000-015-cfbc67df         Completed 2022-10-20 23:28:09+02:00 2022-10-20 23:40:19+02:00                       730.0  model-lr-tr-221020-2000     0.7968\n",
       "7   0.000126  model-lr-tr-221020-2000-013-175d72a6         Completed 2022-10-20 22:59:37+02:00 2022-10-20 23:11:46+02:00                       729.0  model-lr-tr-221020-2000     0.7955\n",
       "18  0.000268  model-lr-tr-221020-2000-002-ba9388a9         Completed 2022-10-20 20:16:40+02:00 2022-10-20 20:29:00+02:00                       740.0  model-lr-tr-221020-2000     0.7927\n",
       "8   0.000026  model-lr-tr-221020-2000-012-5ae01165         Completed 2022-10-20 22:45:18+02:00 2022-10-20 22:57:18+02:00                       720.0  model-lr-tr-221020-2000     0.7905"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "from reporting_util import analyze_hpo_job\n",
    "chart, trials_df, full_df = analyze_hpo_job(\n",
    "    md_lr, \n",
    "    return_dfs=True,\n",
    "    job_metrics=[\n",
    "        'Train:Loss',\n",
    "        'Valid:Loss',\n",
    "        'Epoch',\n",
    "        'LearnableParameters'\n",
    "    ]\n",
    ")\n",
    "chart "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "135a6585-345e-440c-b907-65e10da5573f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'XXX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [59]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mXXX\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'XXX' is not defined"
     ]
    }
   ],
   "source": [
    "XXX"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
